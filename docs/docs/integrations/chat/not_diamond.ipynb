{
 "cells": [
  {
   "cell_type": "raw",
   "id": "59148044",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "sidebar_label: Not Diamond\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf733a38-db84-4363-89e2-de6735c37230",
   "metadata": {},
   "source": [
    "# Not Diamond\n",
    "\n",
    "> [Not Diamond](https://www.notdiamond.ai/) automatically determines which model is best-suited to respond to any query, for improved quality, and reduced cost and latency. \n",
    "\n",
    "Langchain supports automatic model routing to all [models supported by Not Diamond](https://notdiamond.readme.io/docs/llm-models) using `ChatNotDiamond`. This notebook covers how to get started with automatic model routing using Langchain + the Not Diamond I/O library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d85984",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d35576",
   "metadata": {},
   "source": [
    "Install the `notdiamond[create]` package that includes `langchain_community` and other langchain modules for generating LLM responses from various providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0133ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet notdiamond[create]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1544fb",
   "metadata": {},
   "source": [
    "Create your [Not Diamond API key](https://app.notdiamond.ai/keys). Set `NOTDIAMOND_API_KEY` environment variable or use the `notdiamond_api_key` keyword argument. Additionally, provide API keys for all providers that you want to route between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3864e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"NOTDIAMOND_API_KEY\"] = \"YOUR_NOTDIAMOND_API_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"YOUR_ANTHROPIC_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955bf4b",
   "metadata": {},
   "source": [
    "Initialize a chat model with routing capabilities using `ChatNotDiamond`. You should include your desired providers and models to route between using `llm_configs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cf04e8-423a-4ff6-8b09-f11fb711c817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatNotDiamond\n",
    "\n",
    "models = ['openai/gpt-4o', 'anthropic/claude-3-5-sonnet-20240620']\n",
    "chat = ChatNotDiamond(llm_configs=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d1cfc",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "`ChatNotDiamond` supports all methods of `ChatModel` including async APIs.\n",
    "\n",
    "You can also use functionality of `invoke`, `generate`, and `stream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8199ef8f-eb8b-4253-9ea0-6c24a013ca4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Diamond session ID:  a0482264-3d71-48fb-b043-c9d428718905\n",
      "LLM called:  anthropic/claude-3-5-sonnet-20240620\n",
      "Response: The translation of \"I love programming\" from English to French is:\n",
      "\n",
      "J'adore la programmation.\n",
      "\n",
      "You can also say:\n",
      "\n",
      "J'aime programmer.\n",
      "\n",
      "Both translations are correct and convey the same meaning. The first one literally means \"I love programming,\" while the second one translates more closely to \"I love to program.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to French. I love programming.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "response = chat(messages)\n",
    "print(\"Not Diamond session ID: \", response.response_metadata['session_id'])  # Unique ID of Not Diamond's recommendation\n",
    "print(\"LLM called: \", response.response_metadata['model_name'])  # LLM routed to\n",
    "print(\"Response:\", response.content) # LLM response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c361ab1e-8c0c-4206-9e3c-9d1424a12b9c",
   "metadata": {},
   "source": [
    "## `ChatNotDiamond` also supports async and streaming functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fac0e9-05a4-4fc1-a3b3-e5bbb24b971b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='Here\\'s the translation of \"I love programming\" from English to French:\\n\\nJ\\'adore programmer.\\n\\nYou could also say:\\n\\nJ\\'aime la programmation.\\n\\nBoth versions are correct and convey the same meaning. The first one is more direct and literally translates to \"I love to program,\" while the second one translates to \"I love programming\" as a noun.', generation_info={'finish_reason': None}, message=AIMessage(content='Here\\'s the translation of \"I love programming\" from English to French:\\n\\nJ\\'adore programmer.\\n\\nYou could also say:\\n\\nJ\\'aime la programmation.\\n\\nBoth versions are correct and convey the same meaning. The first one is more direct and literally translates to \"I love to program,\" while the second one translates to \"I love programming\" as a noun.', response_metadata={'session_id': '0c5b5360-8821-4650-b80b-bee12e3c4d1b', 'model_name': 'anthropic/claude-3-5-sonnet-20240620', 'input_tokens': 20, 'output_tokens': 85, 'total_tokens': 105, 'finish_reason': None}, id='run-ba376009-e8cd-4db0-ad81-8a41edc95c93-0'))]], llm_output={}, run=[RunInfo(run_id=UUID('ba376009-e8cd-4db0-ad81-8a41edc95c93'))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat.agenerate([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025be980-e50d-4a68-93dc-c9c7b500ce34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the translation of \"I love programming\" in French:\n",
      "\n",
      "J'adore la programmation.\n",
      "\n",
      "A few notes:\n",
      "- \"J'adore\" means \"I love\" or \"I adore\"\n",
      "- \"La programmation\" is \"programming\" in French, with \"la\" being the feminine definite article\n",
      "\n",
      "You could also say:\n",
      "J'aime programmer.\n",
      "\n",
      "This version uses \"J'aime\" (I like/love) and the verb form \"programmer\" (to program) instead of the noun form."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here\\'s the translation of \"I love programming\" in French:\\n\\nJ\\'adore la programmation.\\n\\nA few notes:\\n- \"J\\'adore\" means \"I love\" or \"I adore\"\\n- \"La programmation\" is \"programming\" in French, with \"la\" being the feminine definite article\\n\\nYou could also say:\\nJ\\'aime programmer.\\n\\nThis version uses \"J\\'aime\" (I like/love) and the verb form \"programmer\" (to program) instead of the noun form.', id='run-30f9d9bf-e52a-49a6-880f-e6c59643455a')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatNotDiamond(\n",
    "    llm_configs=models,\n",
    "    streaming=True,\n",
    "    verbose=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbef825",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`ChatNotDiamond` also provides structured output and function calling use cases for [models that support these features](https://notdiamond.readme.io/docs/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62ac3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Diamond session ID:  ec5db2c4-2088-4d74-a2db-49ec9d6e82d1\n",
      "LLM called:  anthropic/claude-3-5-sonnet-20240620\n",
      "('Response: [{\\'text\\': \\'To calculate 10 * 12, I can use the \"multiply\" '\n",
      " \"function that\\\\'s available to me. Let me call that function for you.', \"\n",
      " \"'type': 'text'}, {'id': 'toolu_013BFmigdUjH1SaaJiCW83J4', 'input': {'a': 10, \"\n",
      " \"'b': 12}, 'name': 'multiply', 'type': 'tool_use'}]\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from langchain_community.chat_models import ChatNotDiamond\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Defining our tools\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"Adds a and b.\"\n",
    "    return a + b\n",
    "  \n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"Multiplies a and b.\"\n",
    "    return a * b\n",
    "\n",
    "# Define the models to route between and the client\n",
    "models = ['openai/gpt-4o', 'anthropic/claude-3-5-sonnet-20240620', 'google/gemini-1.5-pro-latest']\n",
    "chat = ChatNotDiamond(llm_configs=models)\n",
    "\n",
    "# Binding the add and multiply tools to the client\n",
    "chat.bind_tools([add, multiply]) \n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a bot that helps with math calculations using provided functions. For every question that is asked, call the correct function.\"),\n",
    "    HumanMessage(content=\"What is 10 * 12?\")\n",
    "]\n",
    "\n",
    "# Invoking the chat\n",
    "response = chat(messages)\n",
    "\n",
    "print(\"Not Diamond session ID: \", response.response_metadata['session_id'])  # Unique ID of Not Diamond's recommendation\n",
    "print(\"LLM called: \", response.response_metadata['model_name'])  # LLM routed to\n",
    "pprint(f\"Response: {response.content}\") # LLM response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
